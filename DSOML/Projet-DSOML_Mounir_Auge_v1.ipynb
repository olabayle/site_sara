{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet DSOML : algorithme SDCA appliqué au SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce projet est d'implémenter un algorithme SDCA afin d'estimer un SVM et de le comparer à une descente de sous-gradient. Ce projet s'appuie sur deux articles :\n",
    "* le premier, écrit par Shai Shalev-Shwartz et Tong Zhang en 2013 traite de l'algorithme SDCA et s'intitule \"Stochastic Dual Coordinate Ascent Methods for Regularized Loss Minimization\"\n",
    "* le second, écrit par Shai Shalev-Shwartz et al. traite de l'approche de descente de sous-gradient et s'intitule \"Primal Estimated sub-GrAdient SOlver for SVM\".\n",
    "\n",
    "Nous appliquerons ces deux algorithmes à la base de données suivante : BLABLABLA. Trouver un truc qui marche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
       "<script>\n",
       "function repeat_indent_string(n){\n",
       "    var a = \"\" ;\n",
       "    for ( ; n > 0 ; --n) {\n",
       "        a += \"    \";\n",
       "    }\n",
       "    return a;\n",
       "}\n",
       "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item) {\n",
       "    var anchors = document.getElementsByClassName(\"section\");\n",
       "    if (anchors.length == 0) {\n",
       "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
       "    }\n",
       "    var i,t;\n",
       "    var text_menu = begin;\n",
       "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
       "    var ind = \"\";\n",
       "    var memo_level = 1;\n",
       "    var href;\n",
       "    var tags = [];\n",
       "    var main_item = 0;\n",
       "    for (i = 0; i <= llast; i++) {\n",
       "        tags.push(\"h\" + i);\n",
       "    }\n",
       "\n",
       "    for (i = 0; i < anchors.length; i++) {\n",
       "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
       "\n",
       "        var child = null;\n",
       "        for(t = 0; t < tags.length; t++) {\n",
       "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
       "            if (r.length > 0) {\n",
       "child = r[0];\n",
       "break;\n",
       "            }\n",
       "        }\n",
       "        if (child == null){\n",
       "            text_memo += \"null\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        if (anchors[i].hasAttribute(\"id\")) {\n",
       "            // when converted in RST\n",
       "            href = anchors[i].id;\n",
       "            text_memo += \"#1-\" + href;\n",
       "            // passer à child suivant (le chercher)\n",
       "        }\n",
       "        else if (child.hasAttribute(\"id\")) {\n",
       "            // in a notebook\n",
       "            href = child.id;\n",
       "            text_memo += \"#2-\" + href;\n",
       "        }\n",
       "        else {\n",
       "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        var title = child.textContent;\n",
       "        var level = parseInt(child.tagName.substring(1,2));\n",
       "\n",
       "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
       "\n",
       "        if ((level < lfirst) || (level > llast)) {\n",
       "            continue ;\n",
       "        }\n",
       "        if (title.endsWith('¶')) {\n",
       "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\")\n",
       "        }\n",
       "\n",
       "        if (title.length == 0) {\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        while (level < memo_level) {\n",
       "            text_menu += \"</ul>\\n\";\n",
       "            memo_level -= 1;\n",
       "        }\n",
       "        if (level == lfirst) {\n",
       "            main_item += 1;\n",
       "        }\n",
       "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
       "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
       "            continue;\n",
       "        }\n",
       "        while (level > memo_level) {\n",
       "            text_menu += \"<ul>\\n\";\n",
       "            memo_level += 1;\n",
       "        }\n",
       "        text_menu += repeat_indent_string(level-2) + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
       "    }\n",
       "    while (1 < memo_level) {\n",
       "        text_menu += \"</ul>\\n\";\n",
       "        memo_level -= 1;\n",
       "    }\n",
       "    text_menu += send;\n",
       "    //text_menu += \"\\n\" + text_memo;\n",
       "    return text_menu;\n",
       "};\n",
       "var update_menu = function() {\n",
       "    var sbegin = \"\";\n",
       "    var sformat = '<li><a href=\"#__HREF__\">__TITLE__</a></li>';\n",
       "    var send = \"\";\n",
       "    var keep_item = -1;\n",
       "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item);\n",
       "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
       "    menu.innerHTML=text_menu;\n",
       "};\n",
       "window.setTimeout(update_menu,2000);\n",
       "            </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jyquickhelper import add_notebook_menu\n",
    "add_notebook_menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importations nécessaires \n",
    "import numpy as np\n",
    "import random\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithmes SDCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons utiliser les deux algorithmes intitulés \"Procédure SDCA\" et \"Procédure SDCA-Perm\" du premier article. Chaque procédure utilise la fonction $ \\Phi_i^\\star $. En fonction du cadre d'utilisation de ces algorithmes, cette fonction diffère :\n",
    "* pour un SVM (formule que nous allons utiliser), nous utilisons la hinge loss, nous avons alors $\\Phi_i^\\star(-a)=-a y_i$\n",
    "* pour une régresison quantile, nous utilisons l'absolute deviation loss, nous avons alors $\\Phi_i^\\star(-a)=-a y_i$\n",
    "* pour une régression ridge, nous utilisons la squared loss, nous avons alors $\\Phi_i^\\star(-a)=-a y_i + \\frac{a^2}{4}$\n",
    "* pour une régression logistique, nous utilisons la log loss, nous avons alors $\\Phi_i^\\star(-a)=a y_i \\log(a y_i) + (1-a y_i) \\log(1- a y_i)$\n",
    "\n",
    "Nous avons codé pour chaque cas les quatre fonctions, mais étant donné que nous nous intéressons au cas des SVM, nous allons utiliser uniquement la première."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Algorithme SDCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DeltaAlphaSVMhinge(x,y,w,n,LAMBDA):\n",
    "    return LAMDBA*n*(y-x*w)/(x**2)\n",
    "\n",
    "def DeltaAlphaSVMdeviation(x,y,w,n,LAMBDA):\n",
    "    return LAMDBA*n*(y-x*w)/(x**2)\n",
    "\n",
    "def DeltaAlphaREGsquared(alpha,x,y,w,n,LAMBDA):\n",
    "    return 2*LAMBDA*n*(y-alpha/2-x*w)/(2*x**2+LAMBDA*n)\n",
    "\n",
    "def DeltaAlphaREGlog(alpha,x,y,w,n,LAMBDA):\n",
    "    def FonctionMaximisation(deltaalpha):\n",
    "        return -y*(np.log(y*(alpha+deltaalpha)*(1-(alpha+deltaalpha)*y)))*x*w-x**2*deltaalpha/(LAMDBA*n) \n",
    "    #attention faux cf feuille écrite dans le train\n",
    "    return scipy.optimize.bisect(FonctionMaximisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Procedure SDCA\n",
    "\n",
    "# initialisation\n",
    "# il faut initialiser x et y avec les données que l'on a choisies\n",
    "n_samples, n_features = 100, 10\n",
    "T = 50\n",
    "T0 = T/2\n",
    "w = np.zeros(T)\n",
    "alpha = np.zeros(T) #provient de l'algo SGD modifié\n",
    "LAMBDA = 0.5 #je ne suis pas sûre de la valeur de LAMBDA\n",
    "\n",
    "# itérations\n",
    "for t in range(T):\n",
    "    deltaalpha = 0\n",
    "    i = random.randint(1,n_features+1)\n",
    "    xi = x[i]\n",
    "    yi = y[i]\n",
    "    deltaalpha = DeltaAlphaSVMhinge(xi,yi,w[t-1],n_features,LAMBDA) #On choisit parmi les 4 fonctions au-dessus\n",
    "    alpha[t] = alpha[k-1] + deltaalpha\n",
    "    w[t] = w[k-1] + deltaalpha*xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return - averaging option     \n",
    "alphabarre = 1/(T-T0)*alpha[T0:T].sum() \n",
    "wbarre = 1/(T-T0)*w[T0:T].sum()\n",
    "\n",
    "# return - random option     \n",
    "t = randomrandint(T0+1,T)\n",
    "alphabarre = alpha[t]\n",
    "wbarre = w[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Algorithme SDCA-Perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AlphaSVMhinge(x,y,w,t,LAMBDA):\n",
    "    return LAMDBA*t*(y-x*w)/(x**2)\n",
    "\n",
    "def AlphaSVMdeviation(x,y,w,t,LAMBDA):\n",
    "    return LAMDBA*t*(y-x*w)/(x**2)\n",
    "\n",
    "def AlphaREGsquared(alpha,x,y,w,t,LAMBDA):\n",
    "    return 2*LAMBDA*t*(y-x*w)/(2*x**2+LAMBDA*t)\n",
    "\n",
    "def AlphaREGlog(alpha,x,y,w,t,LAMBDA):\n",
    "    def FonctionMaximisation(alpha):\n",
    "        return -y*np.log(y*alpha*(1-alpha*y))-x*w-x**2*alpha/(LAMDBA*t)\n",
    "    #attention faux cf feuille écrite dans le train\n",
    "    return scipy.optimize.bisect(FonctionMaximisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SGD modifié afin d'obtenir alpha\n",
    "# il faut initialiser x et y avec les données que l'on a choisies\n",
    "n_samples, n_features = 100, 10\n",
    "w=np.zeros(n_samples)\n",
    "somme=0\n",
    "for t in range(1,n_samples+1):\n",
    "    xt = x[t]\n",
    "    yt = y[t]\n",
    "    alpha[t] = AlphaSVMhinge(xt,yt,w[t-1],t,LAMBDA)\n",
    "    somme += alpha[t]*xt\n",
    "    w[t] = somme/(LAMBDA*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def IncDualSVMhinge(alpha,x,y,w,n,LAMBDA):\n",
    "    m = np.max(0,np.min(1,LAMBDA*n*(1-np.transpose(x)*w*y)/np.linalg.norm(x)+alpha*y))\n",
    "    return y*m - alpha\n",
    "\n",
    "def IncDualSVMdeviation(alpha,x,y,w,n,LAMBDA):\n",
    "    np.m = np.max(-1,Nmin(1,LAMBDA*n*(y-np.transpose(x)*w)/np.linalg.norm(x)+alpha))\n",
    "    return m - alpha\n",
    "\n",
    "def IncDualREGsquared(alpha,x,y,w,n,LAMBDA):\n",
    "    m = (y-np.transpose(x)*w-0.5*alpha)/(0.5+np.linalg.norm(x)/(LAMBDA*n))\n",
    "    return m\n",
    "\n",
    "def IncDualREGlog(alpha,x,y,w,n,LAMBDA):\n",
    "    m = ((1+np.exp(np.transpose(x)*w*y))**(-1)*y-alpha)/np.max(1,0.25+np.linalg.norm(x)/(LAMBDA*n)) #attention faux\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Procedure SDCA-Perm\n",
    "\n",
    "# initialisation\n",
    "# il faut initialiser x et y avec les données que l'on a choisies\n",
    "n_samples, n_features = 100, 10\n",
    "T = 50\n",
    "T0 = T/2\n",
    "w = np.zeros(T)\n",
    "alpha = np.zeros(T) #provient de l'algo SGD modifié\n",
    "LAMBDA = 0.5 #je ne suis pas sûre de la valeur de LAMBDA\n",
    "k=0\n",
    "# itérations\n",
    "perm = np.random.permutation(np.arange(1,n_features+1))\n",
    "for j in range(1,n_features+1): #je pense qu'on pourrait éviter de faire cette boucle et de passer en vectoriel\n",
    "                                #je vais y réfléchir\n",
    "    k += 1\n",
    "    deltaalpha=np.zeros(n_features)\n",
    "    i=perm[j]\n",
    "    xi = x[i]\n",
    "    yi = y[i]\n",
    "    deltaalpha[j] = IncDualSVMhinge(alpha[k-1],xi,yi,w[k-1],n_features,LAMBDA) #On choisit parmi les 4 fonctions au-dessus\n",
    "    alpha[k] = alpha[k-1] + deltaalpha*np.ones(n_features)\n",
    "    w[k] = w[k-1] + 1/(n_features*LAMBDA)*deltaalpha*x\n",
    "# Problème car k ne va que jusqu'à n_features du coup... Mais sincèrement je ne comprends pas les itérations de l'algorithme\n",
    "# les variables se mélangent non ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return - averaging option     \n",
    "alphabarre = 1/(T-T0)*alpha[T0:T].sum() \n",
    "wbarre = 1/(T-T0)*w[T0:T].sum()\n",
    "\n",
    "\n",
    "# return - random option     \n",
    "t = random.randint(T0+1,T)\n",
    "alphabarre = alpha[t]\n",
    "wbarre = w[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. Algorithme de descente de sous-gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
